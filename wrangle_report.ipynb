{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d883f46",
   "metadata": {},
   "source": [
    "# Wrangle Report\n",
    "\n",
    "### Introduction\n",
    "The main objective of this project was to wrangle WeRateDogs Twitter data to make inferences and visualizations about dog posts. My task was to wrangle data from the WeRateDogs Twitter and make visualizations and inferences.\n",
    "\n",
    "The objective was to gather, assess, and clean the data. At least Eight quality issues and two tidiness issues are to be assesed and cleaned.\n",
    "I had to wrangle date ie gather,assess and finally clean. After which store, analyze, and visualize the wrangled data and lastly report on my data analysis and visualizations.\n",
    "\n",
    "### Gathering the Data\n",
    "The data for this project was in three different formats:\n",
    "Twitter Archive File – WeRateDogs: This was already provided for download-twitter_archive_enhanced.csv.\n",
    "\n",
    "Image Predictions File: The tweet image predictions, breed of dog present in each tweet according to a\n",
    "neural network. This file (image_predictions.tsv) was on Udacity website and downloaded\n",
    "programmatically using the Requests library from the link https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/imagepredictions.tsv\n",
    "\n",
    "Tweet JSON File: By using the tweet IDs in the WeRateDogs Twitter archive, I queried the\n",
    "Twitter API for each tweet’s JSON data using Pythons tweepy library and stored each tweet's entire set\n",
    "of JSON data in a file called tweet_json.txt file.\n",
    "\n",
    "\n",
    "### Cleaning and Storing  Data\n",
    "\n",
    "After serious assessment of the dataset,i embarked on the cleaning stage of this project.\n",
    "In the twitter archive data, I changed the datatype of timestamp to date and time and made the dog names consistent by first letter capital. The \"rating_denominator\" are supposed to be all 10 which was not the same. I then changed the all to 10. On thr rating_numerator had to change all values which were more than 15,replaced them with values in the range 10-15. I realised the dog_rates(doggo, floofer, pupper, puppo) were in column headers which i had to correct.\n",
    "From tweet JSON data, I sliced the retweet_count and favorite_count columns which were the main data needed.\n",
    "I merged the three datasets into one(twitter archive file, tweet json file and the image prediction file), twitter_archive_master.csv.\n",
    "\n",
    "## Conclusion\n",
    "The project is well diversed as to where the data is and knowing what is required to access them. Wrangling is the main task in this project and finally visualization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
